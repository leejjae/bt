{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0809ee-1a2e-4059-a847-9c9512c98d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from dataset import DataManager\n",
    "\n",
    "import resnet50 as resnet_models\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691fc14-24ba-44c6-b609-3c7ffa0e7866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66e32e-4129-46dd-b1d4-56ffa7bfc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Implementation of SwAV\")\n",
    "        \n",
    "    #########################\n",
    "    #### data parameters ####\n",
    "    #########################\n",
    "    parser.add_argument(\"--data_set\", type=str, default=\"cifar\",\n",
    "                        help=\"dataset\")\n",
    "    parser.add_argument(\"--nmb_crops\", type=int, default=[2], nargs=\"+\",\n",
    "                        help=\"list of number of crops (example: [2, 6])\")\n",
    "    parser.add_argument(\"--size_crops\", type=int, default=[32], nargs=\"+\",\n",
    "                        help=\"crops resolutions (example: [224, 96])\")\n",
    "    parser.add_argument(\"--min_scale_crops\", type=float, default=[0.14], nargs=\"+\",\n",
    "                        help=\"argument in RandomResizedCrop (example: [0.14, 0.05])\")\n",
    "    parser.add_argument(\"--max_scale_crops\", type=float, default=[1], nargs=\"+\",\n",
    "                        help=\"argument in RandomResizedCrop (example: [1., 0.14])\")\n",
    "    parser.add_argument(\"--prior\", type=float, default=0.5,\n",
    "                        help=\"positive prior\")\n",
    "    \n",
    "    \n",
    "    ##########################\n",
    "    #### train parameters ####\n",
    "    ##########################\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100)\n",
    "    parser.add_argument(\"--arch\", type=str, default='resnet50')\n",
    "    parser.add_argument(\"--hidden_mlp\", type=int, default=2048)\n",
    "    parser.add_argument(\"--feat_dim\", type=int, default=128)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f540d-95ef-474a-9a8a-9a7e2a4cd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeds(seed=42):\n",
    "    \"\"\"\n",
    "    Fix random seeds.\n",
    "    \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab0d39-fc60-4d47-8c62-47f6cf9aac4b",
   "metadata": {},
   "source": [
    "# set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f2b51-8e26-4fa0-8cfe-6ef433f1dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = ['script.py',\n",
    "    '--data_set', 'living17',\n",
    "    '--hidden_mlp', '2048',\n",
    "    '--feat_dim', '128',\n",
    "    '--arch', 'resnet50',\n",
    "    '--prior', '0.5',\n",
    "    '--seed', '42',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc05f6-98da-44de-97ed-e7dff4fba3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52dce1-5253-4fcb-b185-390e69ab1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = DataManager(train_dataset = 'living17',\n",
    "                      test_dataset = args.data_set,\n",
    "                      batch_size = 64,\n",
    "                      train_prior = args.prior,\n",
    "                      test_prior = 1. - args.prior)\n",
    "mv_dataset, sv_dataset, train_dataset, observed_subset, test_dataset = manager.get_data()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b24aa4-4332-4af2-ba6c-22a2636425cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.data_set in ['cifarv2', 'cifar10c', 'cinic']:\n",
    "    args.mean = [0.4914, 0.4822, 0.4465]\n",
    "    args.std = [0.2470, 0.2435, 0.2616]\n",
    "    args.channels = 3\n",
    "elif args.data_set in ['usps', 'svhn']:\n",
    "    args.mean = [0.5]\n",
    "    args.std = [0.5]\n",
    "    args.channels = 1\n",
    "elif args.data_set in ['entity13', 'living17']:\n",
    "    args.mean = [0.485, 0.456, 0.406]\n",
    "    args.std = [0.229, 0.224, 0.225]\n",
    "    args.channels = 3\n",
    "elif args.data_set == 'camelyon17':\n",
    "    args.mean = None\n",
    "    args.std = None\n",
    "    args.channels = 3\n",
    "else:\n",
    "    raise TypeError(\"no \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236a5ca-27af-47c1-bef5-efabc43db65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4c14d-87ee-4b73-ba4d-d59f97066c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51fb70-b188-4398-9be9-e31c3cb278aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da253d8-101c-49c9-9ddd-50e94465dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351b987-bc60-4272-8538-bfce632082a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9c4f2-5ac6-4c38-8ea2-615132d51f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee568e13-74b6-415a-8ddc-59850b531564",
   "metadata": {},
   "source": [
    "# load CL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7833ed9-92dd-420b-9eee-d756ed779697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def get_models(base_path):\n",
    "    # base_path 아래의 args.data_set 폴더 경로\n",
    "    folder_path = os.path.join(base_path, args.data_set)\n",
    "    \n",
    "    # prior + seed 조건 패턴\n",
    "    pattern = f\"{args.data_set}_{args.prior}_{args.seed}*.pth\"\n",
    "    ckpt_pth = sorted(glob.glob(os.path.join(folder_path, pattern)))\n",
    "\n",
    "    models = []\n",
    "    for pth in ckpt_pth:\n",
    "        state_dict = torch.load(pth, map_location=\"cpu\")  # state_dict만 저장했으므로 바로 로드\n",
    "        model = resnet_models.__dict__[args.arch](\n",
    "            normalize=True,\n",
    "            hidden_mlp=args.hidden_mlp,\n",
    "            output_dim=args.feat_dim,\n",
    "            in_channels=args.channels\n",
    "        )\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "\n",
    "    return ckpt_pth, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97f6f7-65e3-4114-9d52-f6a6820c2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_pth, models = get_models('./model_log_l4_con')\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2e0b3-710b-42cb-a523-7e5c22cbed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f481d4-bf1c-4bb4-8e17-2cd3ec31fb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8da62f-47e1-4b54-98bd-eea50d84846d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5072f81-c2e1-47ac-b379-c511d22c0044",
   "metadata": {},
   "source": [
    "# Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16147145-5233-49d0-b4e4-8ef78f8a9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 메트릭 계산\n",
    "# ------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def compute_metrics(loader, cl_model, classifier, device):\n",
    "    classifier.eval()\n",
    "    cl_model.eval()\n",
    "\n",
    "    all_preds, all_targets, all_probs = [], [], []\n",
    "    for images, labels, _ in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = labels[0].to(device, non_blocking=True)\n",
    "\n",
    "        feats = cl_model.forward_backbone(images)\n",
    "        logits = classifier(feats).squeeze(-1)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        preds = (logits > 0).long()\n",
    "\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "        all_probs.append(probs.cpu())\n",
    "\n",
    "    if len(all_targets) == 0:\n",
    "        return 0.0, 0.0, 0.0, 0, 0.0\n",
    "\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "\n",
    "    acc = float((all_preds == all_targets).mean())\n",
    "    macro_f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    pos_count = int(all_preds.sum())\n",
    "    try:\n",
    "        auc = roc_auc_score(all_targets, all_probs)\n",
    "    except ValueError:\n",
    "        auc = 0.0\n",
    "    return acc, macro_f1, pos_count, auc\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 버퍼 없는 ModelEMA (파라미터만 EMA)\n",
    "# ------------------------------------------------------------\n",
    "class ModelEMA(nn.Module):\n",
    "    \"\"\"\n",
    "    - ema_model을 deepcopy로 보관하고 학습은 하지 않는다.\n",
    "    - 매 step 후 update(base_model)로 ema_model 파라미터만 지수평균 갱신한다.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, decay: float = 0.999):\n",
    "        super().__init__()\n",
    "        self.decay = float(decay)\n",
    "        self.ema_model = deepcopy(model)\n",
    "        for p in self.ema_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.ema_model.eval()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, base_model: nn.Module):\n",
    "        for p_src, p_ema in zip(base_model.parameters(), self.ema_model.parameters()):\n",
    "            if not p_src.requires_grad:\n",
    "                continue\n",
    "            p_ema.data.mul_(self.decay).add_(p_src.data, alpha=1.0 - self.decay)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ema_model(x)\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        self.ema_model.to(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        self.ema_model.eval()\n",
    "        return super().eval()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 메인 학습 루프\n",
    "# ------------------------------------------------------------\n",
    "def pre_main(\n",
    "    cl_model: nn.Module,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    *,\n",
    "    epochs: int = 100,\n",
    "    lr: float = 1e-3,\n",
    "    neg_weight: float = 0.1,\n",
    "    use_ema: bool = True,\n",
    "    ema_decay: float = 0.999,\n",
    "    ema_start_epoch: int = 10,\n",
    "    eval_with_ema_only: bool = False  # True면 출력은 EMA 기준으로만\n",
    "):\n",
    "    \"\"\"\n",
    "    - 학습: base classifier로만 업데이트\n",
    "    - step 후: ema_model.update(base)로 EMA 파라미터 갱신\n",
    "    - 평가: ema_start_epoch 이후엔 ema_model로 평가(옵션에 따라 base도 함께 출력)\n",
    "    \"\"\"\n",
    "    global args\n",
    "    device = 'cuda'\n",
    "\n",
    "    # 1) backbone 고정\n",
    "    cl_model.to(device).eval()\n",
    "    for p in cl_model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # 2) classifier (base)\n",
    "    feature_dim = 16 if getattr(args, \"arch\", \"\") == \"lenet\" else 2048\n",
    "    classifier = nn.Linear(feature_dim, 1).to(device)\n",
    "\n",
    "    # 3) 손실 / 옵티마이저\n",
    "    pn_loss = nn.BCEWithLogitsLoss(reduction='none').to(device)\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=lr)\n",
    "\n",
    "    # 4) EMA 모델(teacher)\n",
    "    ema_model = ModelEMA(classifier, decay=ema_decay).to(device) if use_ema else None\n",
    "\n",
    "    # -------------------------\n",
    "    # 학습 루프\n",
    "    # -------------------------\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        classifier.train()\n",
    "        cl_model.eval()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for images, labels, _ in train_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            y_pu = labels[1].to(device, non_blocking=True)   # {+1, -1}\n",
    "            targets = (y_pu == 1).float()                   # {1, 0}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                feats = cl_model.forward_backbone(images)\n",
    "\n",
    "            logits = classifier(feats).squeeze(-1)\n",
    "            per_sample_loss = pn_loss(logits, targets)\n",
    "\n",
    "            # negative 샘플 가중치\n",
    "            weights = torch.ones_like(per_sample_loss)\n",
    "            weights = torch.where(targets == 0,\n",
    "                                  torch.full_like(per_sample_loss, float(neg_weight)),\n",
    "                                  weights)\n",
    "            loss = (weights * per_sample_loss).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # EMA 파라미터 갱신\n",
    "            if use_ema and epoch >= ema_start_epoch:\n",
    "                ema_model.update(classifier)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_loss = total_loss / max(1, num_batches)\n",
    "\n",
    "        # -------------------------\n",
    "        # 평가 & 로그 출력\n",
    "        # -------------------------\n",
    "        tag = \"EMA-ON\" if (use_ema and epoch >= ema_start_epoch) else \"EMA-OFF\"\n",
    "        \n",
    "        if use_ema and epoch >= ema_start_epoch:\n",
    "            # EMA 메트릭\n",
    "            tr_acc_e, tr_mf1_e, tr_pos_e, tr_auc_e = compute_metrics(\n",
    "                train_loader, cl_model, ema_model, device\n",
    "            )\n",
    "            te_acc_e, te_mf1_e, te_pos_e, te_auc_e = compute_metrics(\n",
    "                test_loader, cl_model, ema_model, device\n",
    "            )\n",
    "        \n",
    "        # BASE 메트릭(항상 계산)\n",
    "        tr_acc_b, tr_mf1_b, tr_pos_b, tr_auc_b = compute_metrics(\n",
    "            train_loader, cl_model, classifier, device\n",
    "        )\n",
    "        te_acc_b, te_mf1_b, te_pos_b, te_auc_b = compute_metrics(\n",
    "            test_loader, cl_model, classifier, device\n",
    "        )\n",
    "\n",
    "        print('='*70, flush=True)\n",
    "        if use_ema and epoch >= ema_start_epoch and not eval_with_ema_only:\n",
    "            # ----- BASE + EMA 둘 다 출력 -----\n",
    "            print(\n",
    "                f\"[Epoch {epoch:3d}/{epochs}] [{tag}]\\n\"\n",
    "                f\"Loss: {avg_loss:.4f}\\n\"\n",
    "                f\"(BASE) Train Acc: {tr_acc_b:.4f}  Macro-F1: {tr_mf1_b:.4f}  AUC: {tr_auc_b:.4f}  Pos#: {tr_pos_b} |\\n\"\n",
    "                f\"(BASE) Test  Acc: {te_acc_b:.4f}  Macro-F1: {te_mf1_b:.4f}  AUC: {te_auc_b:.4f}  Pos#: {te_pos_b} |\\n\"\n",
    "                f\"(EMA)  Train Acc: {tr_acc_e:.4f}  Macro-F1: {tr_mf1_e:.4f}  AUC: {tr_auc_e:.4f}  Pos#: {tr_pos_e} |\\n\"\n",
    "                f\"(EMA)  Test  Acc: {te_acc_e:.4f}  Macro-F1: {te_mf1_e:.4f}  AUC: {te_auc_e:.4f}  Pos#: {te_pos_e} |\\n\",\n",
    "                flush=True\n",
    "            )\n",
    "        elif use_ema and epoch >= ema_start_epoch and eval_with_ema_only:\n",
    "            # ----- EMA만 출력 -----\n",
    "            print(\n",
    "                f\"[Epoch {epoch:3d}/{epochs}] [{tag}]\\n\"\n",
    "                f\"Loss: {avg_loss:.4f}\\n\"\n",
    "                f\"(EMA) Train Acc: {tr_acc_e:.4f}  Macro-F1: {tr_mf1_e:.4f}  AUC: {tr_auc_e:.4f}  Pos#: {tr_pos_e} |\\n\"\n",
    "                f\"(EMA) Test  Acc: {te_acc_e:.4f}  Macro-F1: {te_mf1_e:.4f}  AUC: {te_auc_e:.4f}  Pos#: {te_pos_e} |\\n\",\n",
    "                flush=True\n",
    "            )\n",
    "        else:\n",
    "            # ----- BASE만 출력 -----\n",
    "            print(\n",
    "                f\"[Epoch {epoch:3d}/{epochs}] [{tag}]\\n\"\n",
    "                f\"Loss: {avg_loss:.4f}\\n\"\n",
    "                f\"(BASE) Train Acc: {tr_acc_b:.4f}  Macro-F1: {tr_mf1_b:.4f}  AUC: {tr_auc_b:.4f}  Pos#: {tr_pos_b} |\\n\"\n",
    "                f\"(BASE) Test  Acc: {te_acc_b:.4f}  Macro-F1: {te_mf1_b:.4f}  AUC: {te_auc_b:.4f}  Pos#: {te_pos_b} |\\n\",\n",
    "                flush=True\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    return classifier, ema_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d567e03-871e-4a70-9e15-7c7c89e3e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_model = deepcopy(models[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc6f7a-1468-4dcd-844c-9da1cec0fe79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c0912-ffdf-4a2d-9503-bdabdf32c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=512,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98752e-2775-416b-9b71-c4a152304e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_clf, pre_ema = pre_main(cl_model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17129131-22d7-4330-9362-dbd9421f9caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077cc19d-a3c0-4b0e-931c-817d43fee3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca8c73fe-0b69-4c40-bda1-2ac2c9d1a045",
   "metadata": {},
   "source": [
    "# 오분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d678785-64b9-433b-b1d9-e23a0da4e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def to_numpy(x):\n",
    "    if hasattr(x, \"detach\"):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    elif torch.is_tensor(x):\n",
    "        x = x.cpu().numpy()\n",
    "    return x\n",
    "\n",
    "def extract_embeddings(model, loader):\n",
    "    embeddings, labels_pn, labels_pu = [], [], []\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in loader:\n",
    "            y_pn, y_pu = y\n",
    "            x = x.to('cuda')\n",
    "            feat = model.forward_backbone(x)\n",
    "            embeddings.append(feat.cpu())\n",
    "            labels_pn.append(y_pn)\n",
    "            labels_pu.append(y_pu)\n",
    "\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels_pn = torch.cat(labels_pn)\n",
    "    labels_pu = torch.cat(labels_pu)\n",
    "\n",
    "    return embeddings, labels_pn, labels_pu\n",
    "\n",
    "def _save_under_mb(fig, base_path, dpi=300, max_mb=4):\n",
    "    \"\"\"fig를 base_path.(png/jpg/webp) 중 하나로 저장하되, 최종 파일이 max_mb 이하여야 함.\"\"\"\n",
    "    target_bytes = max_mb * 1024 * 1024\n",
    "\n",
    "    # 1) 우선 PNG로 저장\n",
    "    png_path = base_path + \".png\"\n",
    "    fig.savefig(png_path, dpi=dpi, bbox_inches='tight', facecolor='white')\n",
    "    if os.path.getsize(png_path) <= target_bytes:\n",
    "        return png_path\n",
    "\n",
    "    # 2) PNG 팔레트 양자화(256색)로 용량 감소\n",
    "    img = Image.open(png_path).convert(\"RGB\")\n",
    "    quant = img.quantize(colors=256, method=Image.MEDIANCUT)\n",
    "    quant.save(png_path, optimize=True)\n",
    "    if os.path.getsize(png_path) <= target_bytes:\n",
    "        return png_path\n",
    "\n",
    "    # 3) JPEG로 품질 낮추며 시도\n",
    "    for q in [95, 90, 85, 80, 75, 70, 65, 60]:\n",
    "        jpg_path = base_path + \".jpg\"\n",
    "        img.save(jpg_path, format=\"JPEG\", quality=q, optimize=True, progressive=True)\n",
    "        if os.path.getsize(jpg_path) <= target_bytes:\n",
    "            os.remove(png_path)\n",
    "            return jpg_path\n",
    "\n",
    "    # 4) WebP로도 시도\n",
    "    for q in [90, 80, 70, 60]:\n",
    "        webp_path = base_path + \".webp\"\n",
    "        img.save(webp_path, format=\"WEBP\", quality=q, method=6)\n",
    "        if os.path.getsize(webp_path) <= target_bytes:\n",
    "            os.remove(png_path)\n",
    "            return webp_path\n",
    "\n",
    "    # 5) 마지막 수단: 다운스케일 + JPEG\n",
    "    w, h = img.size\n",
    "    scale = 0.9\n",
    "    while scale > 0.4:\n",
    "        w2, h2 = int(w * scale), int(h * scale)\n",
    "        down = img.resize((w2, h2), Image.LANCZOS)\n",
    "        down.save(jpg_path, format=\"JPEG\", quality=85, optimize=True, progressive=True)\n",
    "        if os.path.getsize(jpg_path) <= target_bytes:\n",
    "            os.remove(png_path)\n",
    "            return jpg_path\n",
    "        scale -= 0.1\n",
    "\n",
    "    # 그래도 안되면 가장 작은 파일을 반환(실무상 여기까지 오기 힘듦)\n",
    "    sizes = [(p, os.path.getsize(p)) for p in [png_path, jpg_path] if os.path.exists(p)]\n",
    "    return min(sizes, key=lambda x: x[1])[0] if sizes else png_path\n",
    "\n",
    "def visualize_tsne_train_test(model, loader_train, loader_test,\n",
    "                              save_dir='./tsne', save=False,\n",
    "                              dpi=300, max_mb=4):\n",
    "    emb_tr, pn_tr, pu_tr = extract_embeddings(model, loader_train)\n",
    "    emb_te, pn_te, pu_te = extract_embeddings(model, loader_test)\n",
    "\n",
    "    all_emb = torch.cat([emb_tr, emb_te])\n",
    "    emb_2d = TSNE(n_components=2, random_state=42).fit_transform(to_numpy(all_emb))\n",
    "    n_tr = emb_tr.shape[0]\n",
    "    emb_tr_2d = emb_2d[:n_tr]\n",
    "    emb_te_2d = emb_2d[n_tr:]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(18, 18))\n",
    "\n",
    "    # color palette for pn\n",
    "    unique_labels = np.unique(to_numpy(torch.cat([pn_tr, pn_te])))\n",
    "    palette_pn = dict(zip(unique_labels, sns.color_palette(\"hsv\", len(unique_labels))))\n",
    "\n",
    "    # color palette for pu (U=-1, P=1)\n",
    "    palette_pu = {\n",
    "        -1: 'tab:orange',   # U\n",
    "        1: 'tab:blue'       # labeled P\n",
    "    }\n",
    "\n",
    "    # 전체 x, y 범위 계산 + padding\n",
    "    all_x = emb_2d[:, 0]\n",
    "    all_y = emb_2d[:, 1]\n",
    "    x_min, x_max = np.min(all_x), np.max(all_x)\n",
    "    y_min, y_max = np.min(all_y), np.max(all_y)\n",
    "\n",
    "    pad_x = (x_max - x_min) * 0.05\n",
    "    pad_y = (y_max - y_min) * 0.05\n",
    "\n",
    "    x_min -= pad_x\n",
    "    x_max += pad_x\n",
    "    y_min -= pad_y\n",
    "    y_max += pad_y\n",
    "\n",
    "    def plot(ax, emb, labels, title, palette):\n",
    "        labels_np = to_numpy(labels)\n",
    "        sns.scatterplot(\n",
    "            x=emb[:, 0], y=emb[:, 1], hue=labels_np,\n",
    "            palette=palette, alpha=0.6, s=20,\n",
    "            legend='full', ax=ax\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Dim 1\")\n",
    "        ax.set_ylabel(\"Dim 2\")\n",
    "        ax.set_xlim(x_min, x_max)  # 동일한 x축 범위\n",
    "        ax.set_ylim(y_min, y_max)  # 동일한 y축 범위\n",
    "        ax.legend(title=\"Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Train PN\n",
    "    plot(axes[0, 0], emb_tr_2d[pn_tr == 1], pn_tr[pn_tr == 1], \"Train (P)\", palette_pn)\n",
    "    plot(axes[0, 1], emb_tr_2d[pn_tr == 0], pn_tr[pn_tr == 0], \"Train (N)\", palette_pn)\n",
    "    plot(axes[0, 2], emb_tr_2d, pn_tr, \"Train (PN)\", palette_pn)\n",
    "\n",
    "    # Test PN\n",
    "    plot(axes[1, 0], emb_te_2d[pn_te == 1], pn_te[pn_te == 1], \"Test (P)\", palette_pn)\n",
    "    plot(axes[1, 1], emb_te_2d[pn_te == 0], pn_te[pn_te == 0], \"Test (N)\", palette_pn)\n",
    "    plot(axes[1, 2], emb_te_2d, pn_te, \"Test (PN)\", palette_pn)\n",
    "\n",
    "    # Train PU\n",
    "    idx_sorted = torch.arange(len(pu_tr))\n",
    "    idx_sorted = idx_sorted.sort(descending=True).values  # 큰 인덱스부터\n",
    "    plot(axes[2, 0], emb_tr_2d[pu_tr == 1], pu_tr[pu_tr == 1], \"Train (P)\", palette_pu)\n",
    "    plot(axes[2, 1], emb_tr_2d[pu_tr == -1], pu_tr[pu_tr == -1], \"Train (U)\", palette_pu)\n",
    "    plot(axes[2, 2], emb_tr_2d[idx_sorted], pu_tr[idx_sorted], \"Train (PU)\", palette_pu)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # === 저장 ===\n",
    "    if save == True:\n",
    "        if save_dir is not None:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            prior_str = f\"{float(args.prior):g}\" if hasattr(args, \"prior\") else \"prior\"\n",
    "            base = f\"{args.data_set}_{prior_str}_{args.seed}\" if hasattr(args, \"data_set\") else \"tsne\"\n",
    "            base_path = os.path.join(save_dir, base)\n",
    "    \n",
    "            saved = _save_under_mb(fig, base_path, dpi=dpi, max_mb=max_mb)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b6128-c787-4603-ac6c-10f8cd353d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=512,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d0c02-ae98-4647-b1b7-396f2ff19b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tsne_train_test(cl_model, tr_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e658b-6a05-4652-ae08-bbc550dd0e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5b846-e1c2-4af9-ac69-6b84ff25b07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea82639-9e4c-4315-9712-27d743e044a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5b33d-d98b-41e5-a541-b7bcf6db0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def visualize_tsne_train_test2(model, classifier, loader_train, loader_test,\n",
    "                              save_dir='./tsne_wpn', save=False, ema=False,\n",
    "                              dpi=300, max_mb=4):\n",
    "    device = 'cuda'\n",
    "    model, classifier = model.to(device), classifier.to(device)\n",
    "    model.eval(), classifier.eval()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 임베딩 추출 + classifier 예측\n",
    "    # -------------------------------\n",
    "    def extract_with_pred(loader):\n",
    "        feats, pn_labels, pu_labels, preds = [], [], [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y, _ in loader:\n",
    "                y_pn, y_pu = y\n",
    "                x = x.to(device)\n",
    "\n",
    "                feat = model.forward_backbone(x)\n",
    "                logit = classifier(feat).squeeze(-1)\n",
    "                prob = torch.sigmoid(logit)\n",
    "                pred = (prob >= 0.5).long().cpu()\n",
    "\n",
    "                feats.append(feat.cpu())\n",
    "                pn_labels.append(y_pn)\n",
    "                pu_labels.append(y_pu)\n",
    "                preds.append(pred)\n",
    "\n",
    "        return (torch.cat(feats),\n",
    "                torch.cat(pn_labels),\n",
    "                torch.cat(pu_labels),\n",
    "                torch.cat(preds))\n",
    "\n",
    "    emb_tr, pn_tr, pu_tr, pred_tr = extract_with_pred(loader_train)\n",
    "    emb_te, pn_te, pu_te, pred_te = extract_with_pred(loader_test)\n",
    "\n",
    "    all_emb = torch.cat([emb_tr, emb_te])\n",
    "    emb_2d = TSNE(n_components=2, random_state=42).fit_transform(to_numpy(all_emb))\n",
    "    n_tr = emb_tr.shape[0]\n",
    "    emb_tr_2d = emb_2d[:n_tr]\n",
    "    emb_te_2d = emb_2d[n_tr:]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(18, 18))\n",
    "\n",
    "    # PN color palette\n",
    "    unique_labels = np.unique(to_numpy(torch.cat([pn_tr, pn_te])))\n",
    "    palette_list = sns.color_palette(\"dark\", len(unique_labels))\n",
    "    palette_pn = dict(zip(unique_labels, reversed(palette_list)))\n",
    "\n",
    "    # PU color palette\n",
    "    palette_pu = {-1: 'tab:orange', 1: palette_pn[1]}\n",
    "\n",
    "    # 범위 고정\n",
    "    all_x, all_y = emb_2d[:, 0], emb_2d[:, 1]\n",
    "    x_min, x_max = np.min(all_x), np.max(all_x)\n",
    "    y_min, y_max = np.min(all_y), np.max(all_y)\n",
    "    pad_x, pad_y = (x_max-x_min)*0.05, (y_max-y_min)*0.05\n",
    "    x_min, x_max = x_min-pad_x, x_max+pad_x\n",
    "    y_min, y_max = y_min-pad_y, y_max+pad_y\n",
    "\n",
    "\n",
    "    def lighten_color(color, factor=0.5):\n",
    "        \"\"\"\n",
    "        color를 더 밝게 만드는 함수.\n",
    "        factor=0.0 → 원래색, factor=1.0 → 흰색\n",
    "        \"\"\"\n",
    "        base = np.array(mcolors.to_rgb(color))\n",
    "        white = np.array([1, 1, 1])\n",
    "        return tuple(base + (white - base) * factor)\n",
    "        \n",
    "    def plot(ax, emb, labels, preds, title, palette, gt_mode=True):\n",
    "        labels_np = to_numpy(labels)\n",
    "    \n",
    "        if preds is not None and gt_mode:\n",
    "            preds_np = to_numpy(preds)\n",
    "            correct_mask = labels_np == preds_np\n",
    "        else:\n",
    "            correct_mask = np.ones_like(labels_np, dtype=bool)\n",
    "    \n",
    "        # 색상 통일 (RGB 튜플)\n",
    "        colors = np.array([mcolors.to_rgb(palette[l]) for l in labels_np])\n",
    "    \n",
    "        # 맞은 샘플\n",
    "        ax.scatter(\n",
    "            emb[correct_mask, 0], emb[correct_mask, 1],\n",
    "            c=colors[correct_mask], alpha=0.6, s=20, marker=\"o\", label=None\n",
    "        )\n",
    "    \n",
    "        # 틀린 샘플\n",
    "        light_colors = [lighten_color(c, factor=0.6) for c in colors[~correct_mask]]\n",
    "        ax.scatter(\n",
    "            emb[~correct_mask, 0], emb[~correct_mask, 1],\n",
    "            c=light_colors, alpha=0.6, s=20, marker=\"o\",\n",
    "            label=None\n",
    "        )\n",
    "    \n",
    "        ax.set_facecolor(\"gray\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_xlabel(\"Dim 1\")\n",
    "        ax.set_ylabel(\"Dim 2\")\n",
    "    \n",
    "        # 범례\n",
    "        handles = []\n",
    "        for l in np.unique(labels_np):\n",
    "            handles.append(\n",
    "                plt.Line2D([], [], marker=\"o\", color=palette[l],\n",
    "                           linestyle=\"\", label=str(l))\n",
    "            )\n",
    "        ax.legend(handles=handles, title=\"Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "    # Train PN\n",
    "    plot(axes[0, 0], emb_tr_2d[pn_tr == 1], pn_tr[pn_tr == 1], pred_tr[pn_tr == 1], \"Train (P)\", palette_pn)\n",
    "    plot(axes[0, 1], emb_tr_2d[pn_tr == 0], pn_tr[pn_tr == 0], pred_tr[pn_tr == 0], \"Train (N)\", palette_pn)\n",
    "    plot(axes[0, 2], emb_tr_2d, pn_tr, pred_tr, \"Train (PN)\", palette_pn)\n",
    "\n",
    "    # Test PN\n",
    "    plot(axes[1, 0], emb_te_2d[pn_te == 1], pn_te[pn_te == 1], pred_te[pn_te == 1], \"Test (P)\", palette_pn)\n",
    "    plot(axes[1, 1], emb_te_2d[pn_te == 0], pn_te[pn_te == 0], pred_te[pn_te == 0], \"Test (N)\", palette_pn)\n",
    "    plot(axes[1, 2], emb_te_2d, pn_te, pred_te, \"Test (PN)\", palette_pn)\n",
    "\n",
    "    # Train PU\n",
    "    # PU 전체를 인덱스 큰 순으로 정렬\n",
    "    idx_sorted = torch.arange(len(pu_tr))\n",
    "    idx_sorted = idx_sorted.sort(descending=True).values  # 큰 인덱스부터\n",
    "    plot(axes[2, 0], emb_tr_2d[pu_tr == 1], pu_tr[pu_tr == 1], None, \"Train (P)\", palette_pu, gt_mode=False)\n",
    "    plot(axes[2, 1], emb_tr_2d[pu_tr == -1], pu_tr[pu_tr == -1], None, \"Train (U)\", palette_pu, gt_mode=False)\n",
    "    plot(axes[2, 2], emb_tr_2d[idx_sorted], pu_tr[idx_sorted], None, \"Train (PU)\", palette_pu, gt_mode=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        prior_str = f\"{float(args.prior):g}\" if hasattr(args, \"prior\") else \"prior\"\n",
    "        if not ema:\n",
    "            base = f\"{args.data_set}_{prior_str}_{args.seed}\" if hasattr(args, \"data_set\") else \"tsne\"\n",
    "        else:\n",
    "            base = f\"{args.data_set}_{prior_str}_EMA_{args.seed}\" if hasattr(args, \"data_set\") else \"tsne\"\n",
    "        base_path = os.path.join(save_dir, base)\n",
    "        _save_under_mb(fig, base_path, dpi=dpi, max_mb=max_mb)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee965d-9a5b-4e83-b4f4-587528946d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tsne_train_test2(cl_model, pre_clf, tr_loader, test_loader, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e15a3-4870-4f5a-8199-e1059c794512",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tsne_train_test2(cl_model, pre_ema, tr_loader, test_loader, save=True, ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884d2fc-b822-4c1f-89df-665286ec91d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "418e5fbf-82e0-4847-a6f7-28d541d95abe",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212d364-0e7a-4a97-af94-3bd3c0110847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b034f48d-9db8-47ef-b4c8-7ef99f2f39a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f60554-7878-4b88-84ce-32493ab180b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
