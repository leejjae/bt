{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e17dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DataManager, make_dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "data_manger = DataManager(train_dataset='mnist',\n",
    "                              test_dataset='usps',\n",
    "                              src_prior=0.5,\n",
    "                              tgt_prior=0.5)\n",
    "    \n",
    "\n",
    "pos_dataset, unl_dataset, val_dataset, test_dataset = data_manger.get_data(merge=False)\n",
    "pd = make_dataset(pos_dataset, 'mnist', batch_size=128, role='weak_train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a13cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_dataset(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    pos_class: List,\n",
    "    neg_class: List = None,\n",
    "    num_labeled: int = 0,\n",
    "    num_unlabeled: int = None,\n",
    "    prior: float = None\n",
    "):\n",
    "    # Positive and Negative data indices\n",
    "    p_data_idx = np.where(np.isin(targets, pos_class))[0]\n",
    "    n_data_idx = np.where(np.isin(targets, neg_class) if neg_class else\n",
    "                          np.isin(targets, pos_class, invert=True))[0]\n",
    "\n",
    "    # Obtain labeled positive data \n",
    "    num_pos_labeled_per_cls = int(num_labeled / len(pos_class))\n",
    "    p_ix = []\n",
    "    for cls in pos_class:\n",
    "        p_cls = np.where(np.isin(targets, cls))[0]\n",
    "        p_ix.extend(np.random.choice(a=p_cls, size=num_pos_labeled_per_cls, replace=False))\n",
    "    p_data = features[p_ix]\n",
    "\n",
    "    # y_true: pos -> 1, neg -> -1\n",
    "    p_labels_true = np.ones(len(p_data), dtype=int)   # labeled pos ground-truth = 1\n",
    "    p_labels = np.ones(len(p_data), dtype=int)        # observed label = 1\n",
    "\n",
    "    # Obtain unlabeled data\n",
    "    if num_unlabeled and prior:\n",
    "        n_pu = int(prior * num_unlabeled)\n",
    "        n_nu = num_unlabeled - n_pu\n",
    "        pu_ix = np.random.choice(a=p_data_idx, size=n_pu,\n",
    "                                 replace=False if n_pu <= len(p_data_idx) else True)\n",
    "        nu_ix = np.random.choice(a=n_data_idx, size=n_nu,\n",
    "                                 replace=False if n_nu <= len(n_data_idx) else True)\n",
    "        u_ix = np.concatenate((pu_ix, nu_ix), axis=0)\n",
    "        u_data = features[u_ix]\n",
    "\n",
    "        # ground-truth\n",
    "        y_true = np.concatenate((np.ones(len(pu_ix), dtype=int), -np.ones(len(nu_ix), dtype=int)))\n",
    "        # observed unlabeled\n",
    "        y = np.zeros(len(u_data), dtype=int)\n",
    "\n",
    "    else:\n",
    "        remaining_p_ix = np.setdiff1d(p_data_idx, p_ix)\n",
    "        u_ix = np.concatenate((remaining_p_ix, n_data_idx), axis=0)\n",
    "        u_data = features[u_ix]\n",
    "\n",
    "        # ground-truth\n",
    "        y_true = np.concatenate((np.ones(len(remaining_p_ix), dtype=int), -np.ones(len(n_data_idx), dtype=int)))\n",
    "        # observed unlabeled\n",
    "        y = np.zeros(len(u_data), dtype=int)\n",
    "\n",
    "    # Create final PU dataset\n",
    "    features = np.concatenate((p_data, u_data), axis=0)\n",
    "    y_true = np.concatenate((p_labels_true, y_true), axis=0)  # 1 for pos, -1 for neg\n",
    "    y = np.concatenate((p_labels, y), axis=0)                 # 1 for labeled pos, 0 for unl\n",
    "\n",
    "    # Shuffle and return\n",
    "    features, y_true, y = shuffle(features, y_true, y, random_state=0)\n",
    "    return features, y_true, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binarize_dataset(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    pos_class: List,\n",
    "    neg_class: List=None,\n",
    "    num_labeled: int=0,\n",
    "    num_unlabeled: int=None,\n",
    "    prior: float=None\n",
    "):\n",
    "    # Positive and Negative data indices\n",
    "    p_data_idx = np.where(np.isin(targets, pos_class))[0]\n",
    "    n_data_idx = np.where(np.isin(targets, neg_class) if neg_class else\n",
    "                          np.isin(targets, pos_class, invert=True))[0]\n",
    "\n",
    "    # Obtain labeled positive data \n",
    "    num_pos_labeled_per_cls = int(num_labeled / len(pos_class))\n",
    "    p_ix = []\n",
    "    for cls in pos_class:\n",
    "        p_cls = np.where(np.isin(targets, cls))[0]\n",
    "        p_ix.extend(np.random.choice(a=p_cls, size=num_pos_labeled_per_cls, replace=False))\n",
    "    p_data = features[p_ix]\n",
    "    p_labels = np.ones(len(p_data), dtype=targets.dtype)\n",
    "\n",
    "    # Obtain unlabeled data\n",
    "    if num_unlabeled and prior:\n",
    "        n_pu = int(prior * num_unlabeled)\n",
    "        n_nu = num_unlabeled - n_pu\n",
    "        pu_ix = np.random.choice(a=p_data_idx, size=n_pu,\n",
    "                                 replace=False if n_pu <= len(p_data_idx) else True)\n",
    "        nu_ix = np.random.choice(a=n_data_idx, size=n_nu,\n",
    "                                 replace=False if n_nu <= len(n_data_idx) else True)\n",
    "        u_ix = np.concatenate((pu_ix, nu_ix), axis=0)\n",
    "        u_data = features[u_ix]\n",
    "\n",
    "        y_true = np.concatenate((np.ones(len(pu_ix), dtype=int), -np.ones(len(nu_ix), dtype=int)))\n",
    "        y = np.zeros(len(u_data), dtype=int)\n",
    "    else:\n",
    "        remaining_p_ix = np.setdiff1d(p_data_idx, p_ix)\n",
    "        u_ix = np.concatenate((remaining_p_ix, n_data_idx), axis=0)\n",
    "        u_data = features[u_ix]\n",
    "\n",
    "        y_true = np.concatenate((np.ones(len(remaining_p_ix), dtype=int), -np.ones(len(n_data_idx), dtype=int)))\n",
    "        y = np.zeros(len(u_data), dtype=int)\n",
    "\n",
    "\n",
    "\n",
    "    # Create final PU dataset\n",
    "    features = np.concatenate((p_data, u_data), axis=0)\n",
    "    y_true = np.concatenate((np.ones(len(p_data), dtype=int), y_true), axis=0)\n",
    "    y = np.concatenate((p_labels, y), axis=0)\n",
    "\n",
    "    # Shuffle and return\n",
    "    features, y_true, y = shuffle(features, y_true, y, random_state=0)\n",
    "    return features, y_true, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bedf3742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.354999999999999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1914/60) * 27)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38981cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 1,      # 3으로 바꾸면 RGB\n",
    "        normalize: bool = False,   # ℓ2-정규화 여부\n",
    "        output_dim: int = 0,       # projection head 출력 차원(0이면 사용 안 함)\n",
    "        hidden_mlp: int = 0,       # 0이면 1-layer, >0이면 2-layer MLP\n",
    "        nmb_prototypes=0,          # int or list for multi-head\n",
    "        eval_mode: bool = False,   # backbone feature map까지만 리턴\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.eval_mode = eval_mode\n",
    "        self.l2norm = normalize\n",
    "\n",
    "        # ────── Backbone ──────\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(6)\n",
    "        self.pool1 = nn.MaxPool2d(2)          # ½ 크기\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Global average pooling으로 입력 크기 자유화\n",
    "        self.gap   = nn.AdaptiveAvgPool2d((1, 1))  # (B,16,1,1) → (B,16)\n",
    "        feat_dim   = 16\n",
    "\n",
    "        # ────── Projection head ──────\n",
    "        if output_dim == 0:\n",
    "            self.projection_head = None\n",
    "        elif hidden_mlp == 0:\n",
    "            self.projection_head = nn.Linear(feat_dim, output_dim)\n",
    "        else:\n",
    "            self.projection_head = nn.Sequential(\n",
    "                nn.Linear(feat_dim, hidden_mlp),\n",
    "                nn.BatchNorm1d(hidden_mlp),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(hidden_mlp, output_dim),\n",
    "            )\n",
    "\n",
    "        # ────── Prototype layer ──────\n",
    "        self.prototypes = None\n",
    "        if isinstance(nmb_prototypes, list):\n",
    "            self.prototypes = MultiPrototypes(output_dim, nmb_prototypes)\n",
    "        elif isinstance(nmb_prototypes, int) and nmb_prototypes > 0:\n",
    "            self.prototypes = nn.Linear(output_dim, nmb_prototypes, bias=False)\n",
    "\n",
    "        # Kaiming 초기화\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    # ───────────────────────────\n",
    "    # ―― forward 단계 분리 ―――――――\n",
    "    # ───────────────────────────\n",
    "    def forward_backbone(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        if self.eval_mode:\n",
    "            return x                          # feature map 그대로\n",
    "        x = self.gap(x).flatten(1)           # (B,16)\n",
    "        return x\n",
    "\n",
    "    def forward_head(self, x: torch.Tensor):\n",
    "        if self.projection_head is not None:\n",
    "            x = self.projection_head(x)\n",
    "        if self.l2norm:\n",
    "            x = F.normalize(x, dim=1, p=2)\n",
    "        if self.prototypes is not None:\n",
    "            return x, self.prototypes(x)\n",
    "        return x\n",
    "\n",
    "    # ───────────────────────────\n",
    "    # ―― 멀티-크롭 입력 처리 ―――\n",
    "    # ───────────────────────────\n",
    "    def forward(self, inputs):\n",
    "        # SwAV 구현처럼 inputs가 [crop₁, crop₂, …] 리스트일 때 처리\n",
    "        if not isinstance(inputs, list):\n",
    "            inputs = [inputs]\n",
    "\n",
    "        # 동일 공간해상도끼리 묶어서 한 번에 backbone 처리\n",
    "        sizes = torch.tensor([inp.shape[-1] for inp in inputs])\n",
    "        idx_crops = torch.cumsum(torch.unique_consecutive(sizes, return_counts=True)[1], 0)\n",
    "\n",
    "        start = 0\n",
    "        for end in idx_crops:\n",
    "            _out = self.forward_backbone(torch.cat(inputs[start:end]).cuda(non_blocking=True))\n",
    "            output = _out if start == 0 else torch.cat((output, _out))\n",
    "            start = end\n",
    "\n",
    "        return self.forward_head(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "match",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
